generation:
  direct_path: null
  epoch: best
  weight_path: train
inference:
  direct_path: null
  epoch: best
  weight_path: train
run:
  checkpoint: test_SPDETR_lab6_b32_0.00005_pruning_01
  device_num: "0"
  loader:
    target_labels:
      - 6
    batch_size: 32
    drop_last: true
    num_workers: 4
    pin_memory: true
    detector: true
    dataset:
      name: amos22
      root: /home/work/.dataset/Amos22_RAS/
      scale: 128
      image_scale: 128
      label_scale: 128
      slice_scale: 128
      bbox_scale: 128
  model:
    args:
      args:
        backbone_name: resnet34
        dilation: False
        position_embedding: sine    #sine, learned
        enc_layers: 4
        dec_layers: 4
        dim_feedforward: 2048
        hidden_dim: 256
        dropout: 0.1
        nheads: 8
        num_queries: 1 #1
        pre_norm: True
        aux_loss: False
        num_classes: 1
        lr_backbone: 0.00001
        masks: False
    name: SPDETR_pruning
    type: det #det, seg, comb
  work_dir: /home/work/Result/roi_dyseg/
train:
  loss:
      DETR_Criterion:
        num_classes: 1
        matcher:
          cost_class: 1
          cost_bbox: 5
          cost_giou: 5
        weight_dict:
          loss_ce: 1
          loss_bbox: 5
          loss_giou: 5
        eos_coef: 0.1
        losses: [labels, boxes, cardinality]
        nf_penalty: False


  metrics:
    DiceMetric:
      include_background: true
      reduction: mean_batch
      get_not_nans: false
    HausdorffDistanceMetric:
      percentile: 95
      include_background: true
      reduction: mean_batch
      get_not_nans: false
    MeanIoU:
      include_background: true
      reduction: mean_batch
      get_not_nans: false
  optimizer:
    betas:
    - 0.9
    - 0.95
    lr: 0.00005 #0.002 #0.0025
    opt: adamw
    weight_decay: 0.05
  resume: null
  save_cycle: 500
  scheduler:
    max_epochs: 100000
    warmup_epochs: 5
